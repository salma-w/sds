{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6\n",
    "\n",
    "## The Admin\n",
    "\n",
    "### This is the first of our Agents, and it's responsible for talking to us and administering its memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, Runner, trace\n",
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr\n",
    "from IPython.display import Markdown, display\n",
    "from questions import get_questions_with_no_answer\n",
    "\n",
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"./me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text\n",
    "\n",
    "with open(\"./me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()\n",
    "\n",
    "with open(\"./me/facts.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    facts = json.load(f)\n",
    "\n",
    "full_name = facts[\"full_name\"]\n",
    "name = facts[\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = f\"\"\"\n",
    "# Your Role\n",
    "\n",
    "You are an Administrator Agent.\n",
    "You are part of an Agent Team that is responsible for answering questions about {full_name}, who goes by {name}.\n",
    "\n",
    "## Important Context\n",
    "\n",
    "Here is some basic information about {name}:\n",
    "{facts}\n",
    "\n",
    "Here is a summary of {name}:\n",
    "{summary}\n",
    "\n",
    "Here is the LinkedIn profile of {name}:\n",
    "{linkedin}\n",
    "\n",
    "## Your task\n",
    "\n",
    "As Admin Agent, you are chatting directly with {full_name} who you should address as {name}. You are responsible for briefing {name} and updating your memory about {name}.\n",
    "\n",
    "Here is a list of questions from users for {name} that have not been answered with their question id:\n",
    "\n",
    "{get_questions_with_no_answer()}\n",
    "\n",
    "## Your tools\n",
    "\n",
    "You have access to the following memory related tools:\n",
    "- Tools to manage the long term memory in a Graph database with entities and relationships. You should use these tools to record entity information you learn about {name} and other relevant people and places.\n",
    "- Tools to manage memory using a Qdrant vector database. These tools let you look up and keep memories.\n",
    "\n",
    "You should use both these tools together to record new information you learn; it's good to record information in both places.\n",
    "\n",
    "If {name} offers to answer questions that have not been answered, you can mention those on your list.\n",
    "Then if {name} is able to provide an answer, you should use your tool to record the answer to the question, and also update your graph memory and your Qdrant memory to reflect your new knowledge.\n",
    "\n",
    "To be clear: every time {name} answers one of these questions, you should record the answer to the question being careful to specify the right question id,\n",
    "and also update your graph memory and your Qdrant memory to reflect your new knowledge.\n",
    "\n",
    "You also have tools to list people that have asked to get in touch with {name} that you can provide if asked.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Now with this context, proceed with your conversation with {name}.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(instructions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcp_servers import memory_graph_server, memory_rag_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from questions import get_questions_tools\n",
    "from contacts import get_people_who_want_to_get_in_touch\n",
    "tools = get_questions_tools() + [get_people_who_want_to_get_in_touch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat(message, history):\n",
    "    messages = [{\"role\": m[\"role\"], \"content\": m[\"content\"]} for m in history]\n",
    "    messages += [{\"role\": \"user\", \"content\": message}]\n",
    "    with trace(\"Admin\"):\n",
    "        async with memory_rag_server() as rag_server:\n",
    "            async with memory_graph_server() as graph_server:\n",
    "                agent = Agent(\"Admin\", instructions=instructions, model=\"gpt-4.1\", tools=tools, mcp_servers=[rag_server, graph_server])\n",
    "                result = Runner.run_streamed(agent, messages)\n",
    "                reply = \"\"\n",
    "                async for event in result.stream_events():\n",
    "                    if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
    "                        reply += event.data.delta\n",
    "                        yield reply\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    \"Are there any questions that are not answered yet?\",\n",
    "    \"Has anyone asked to get in touch with me?\",\n",
    "    \"Please summarize your memory of me\",\n",
    "]\n",
    "\n",
    "auth = [(\"admin\", \"admin\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\", examples=examples).launch(auth=auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
