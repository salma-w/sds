{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "175760a6",
   "metadata": {},
   "source": [
    "# Welcome to Week 2!\n",
    "\n",
    "## Agenda\n",
    "\n",
    "### Part 1: Logistics\n",
    "\n",
    "1. Navigating the repo\n",
    "2. Introduction to the material\n",
    "3. Teams, branches\n",
    "4. Assignments\n",
    "\n",
    "### Part 2: RAG\n",
    "\n",
    "1. RAG lab\n",
    "2. Divide into teams\n",
    "3. Reproduce in your teams\n",
    "\n",
    "### Part 3: It's not a competition (yes it is)\n",
    "\n",
    "1. Come up with a plan\n",
    "2. Experiment!\n",
    "3. Start working on the solution\n",
    "4. Reconvene for progress update\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29c4860",
   "metadata": {},
   "source": [
    "# Before we start\n",
    "\n",
    "## A sidebar on Hallucinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44d759d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67263fc",
   "metadata": {},
   "source": [
    "## Hallucinations\n",
    "\n",
    "For an AI User: Hallucinations are the model's problem\n",
    "\n",
    "For an AI Engineer: Hallucinations are *our* problem.\n",
    "\n",
    "Taken to an extreme, it's easy to force an LLM to give a hallucination by boxing it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66d1d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 5 * 11 * 47 * 307\n",
    "\n",
    "question = f\"What are the prime factors of {number}? Reply only with the answer.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n",
    "\n",
    "response = openai.chat.completions.create(model=\"gpt-4.1-mini\", messages=messages)\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf9c4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Strictly reply only with the name of a 5 star hotel in Governor's Island, New York\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n",
    "\n",
    "for i in range(10):\n",
    "    response = openai.chat.completions.create(model=\"gpt-4.1-nano\", messages=messages)\n",
    "    print(response.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2945d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "bootcampers = [\"Seb\", \"Kinjal\", \"Marylou\", \"Dave\", \"Jeff\", \"Rohit\", \"Salma\", \"Sathiya\", \"Ilya\", \"Oscar\", \"Josh\"]\n",
    "\n",
    "class Team(BaseModel):\n",
    "    name: str = Field(description=\"A motivating, inspiring, one word team name in lowercase that will be the git branch name - make it relevant for bootcampers on their way to being AI Engineering Experts and quite over-the-top!\")\n",
    "    members: list[str] = Field(description=\"The members of the team - make it an even mix of skill levels\")\n",
    "\n",
    "class TeamResponse(BaseModel):\n",
    "    teams: list[Team] = Field(description=\"3 teams of 3-4 people each\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc2ffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = f\"\"\"\n",
    "Please divide up the students on our AI Engineering bootcamp into 3 teams of 3-4 people each.\n",
    "Give each team a hugely inspiring name (over-the-top and somewhat tongue-in-cheek) and a list of members.\n",
    "Here are the students, ordered roughly by their self-identified skill level. Ensure a rougly even mix of skills in each team.\n",
    "{bootcampers}\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": message}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58b29c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = completion(model=\"gpt-5\", messages=messages, response_format=TeamResponse)\n",
    "team_response = TeamResponse.model_validate_json(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85e33e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "announcement = \"## Our Teams!\\n\\n\"\n",
    "for team in team_response.teams:\n",
    "    announcement += f\"### Team: {team.name}\\n\"\n",
    "    announcement += \"  \\n\".join(team.members) + \"\\n\\n\"\n",
    "display(Markdown(announcement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f197f469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
